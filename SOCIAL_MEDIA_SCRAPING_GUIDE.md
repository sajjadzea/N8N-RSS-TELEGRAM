# ğŸ” Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Scraping Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ

## ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ

| Ø´Ø¨Ú©Ù‡ | API Ø±Ø³Ù…ÛŒ | Scraping Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ±ØŸ | Ø³Ø®ØªÛŒ | ØªÙˆØµÛŒÙ‡ |
|------|---------|---------------------|------|-------|
| **Telegram** | âœ… Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø¹Ø§Ù„ÛŒ | âœ… Ø®ÛŒÙ„ÛŒ Ø¢Ø³Ø§Ù† | â­ | **API Ø±Ø³Ù…ÛŒ** |
| **Twitter/X** | ğŸ’° Ù¾ÙˆÙ„ÛŒ Ø´Ø¯Ù‡ | âš ï¸ Ø³Ø®Øª | â­â­â­â­ | API ÛŒØ§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ third-party |
| **Instagram** | ğŸ’° Ù…Ø­Ø¯ÙˆØ¯ | âš ï¸ Ø®ÛŒÙ„ÛŒ Ø³Ø®Øª | â­â­â­â­â­ | Unofficial APIs |
| **LinkedIn** | ğŸ’° Ø¨Ø³ÛŒØ§Ø± Ù…Ø­Ø¯ÙˆØ¯ | âŒ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ ØºÛŒØ±Ù…Ù…Ú©Ù† | â­â­â­â­â­ | ØªÙˆØµÛŒÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ |
| **Facebook** | ğŸ’° Ù…Ø­Ø¯ÙˆØ¯ | âš ï¸ Ø³Ø®Øª | â­â­â­â­ | Graph API |
| **YouTube** | âœ… Ø±Ø§ÛŒÚ¯Ø§Ù† | âœ… Ø¢Ø³Ø§Ù† | â­â­ | **API Ø±Ø³Ù…ÛŒ** |
| **Reddit** | âœ… Ø±Ø§ÛŒÚ¯Ø§Ù† | âœ… Ø¢Ø³Ø§Ù† | â­â­ | **API Ø±Ø³Ù…ÛŒ** |
| **Pinterest** | ğŸ’° Ù…Ø­Ø¯ÙˆØ¯ | âš ï¸ Ù…ØªÙˆØ³Ø· | â­â­â­ | API ÛŒØ§ scraping |

---

## 1ï¸âƒ£ Telegram (Ø¨Ù‡ØªØ±ÛŒÙ† Ú¯Ø²ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†) ğŸš€

### âœ… Ù…Ø²Ø§ÛŒØ§:
- **API Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯**
- Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª rate limit Ø´Ø¯ÛŒØ¯
- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Python, Node.js Ùˆ...
- Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ØŒ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ Ùˆ user Ù‡Ø§ Ù¾ÛŒØ§Ù… Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯

### Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§:

#### Python - Telethon
```python
pip install telethon
```

```python
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest

api_id = 'YOUR_API_ID'
api_hash = 'YOUR_API_HASH'

client = TelegramClient('session', api_id, api_hash)

async def scrape_channel(channel_username):
    await client.start()

    # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„
    messages = await client.get_messages(channel_username, limit=100)

    for message in messages:
        if message.text:
            print(f"Date: {message.date}")
            print(f"Text: {message.text}")
            print("-" * 50)

# Ø§Ø¬Ø±Ø§
with client:
    client.loop.run_until_complete(scrape_channel('@channel_username'))
```

#### Python - Pyrogram (Ø³Ø§Ø¯Ù‡â€ŒØªØ±)
```python
pip install pyrogram
```

```python
from pyrogram import Client

app = Client("my_account", api_id='API_ID', api_hash='API_HASH')

async def main():
    async with app:
        # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„
        async for message in app.get_chat_history("@channel_username", limit=100):
            print(message.text)

app.run(main())
```

### Ù†Ù…ÙˆÙ†Ù‡: Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ Ø¢Ø¨ Ø®Ø±Ø§Ø³Ø§Ù†

```python
#!/usr/bin/env python3
import asyncio
from telethon import TelegramClient
from datetime import datetime
import json

api_id = 'YOUR_API_ID'
api_hash = 'YOUR_API_HASH'

# Ù„ÛŒØ³Øª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·
channels = [
    '@abfa_khorasan',
    '@khorasan_news',
    '@mashhad_news',
]

client = TelegramClient('water_monitor', api_id, api_hash)

async def search_in_channels(keywords):
    await client.start()

    results = []

    for channel in channels:
        try:
            async for message in client.iter_messages(channel, limit=50):
                if message.text:
                    # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
                    if any(keyword in message.text for keyword in keywords):
                        results.append({
                            'channel': channel,
                            'date': message.date.isoformat(),
                            'text': message.text,
                            'link': f"https://t.me/{channel.replace('@', '')}/{message.id}"
                        })
        except Exception as e:
            print(f"Error in {channel}: {e}")

    return results

keywords = ['Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ', 'Ø®Ø±Ø§Ø³Ø§Ù† Ø±Ø¶ÙˆÛŒ', 'Ù‚Ø·Ø¹ÛŒ Ø¢Ø¨']

with client:
    results = client.loop.run_until_complete(search_in_channels(keywords))
    print(json.dumps(results, ensure_ascii=False, indent=2))
```

---

## 2ï¸âƒ£ Twitter/X (Ø³Ø®Øª Ø´Ø¯Ù‡)

### Ù…Ø´Ú©Ù„Ø§Øª:
- API Ø±Ø§ÛŒÚ¯Ø§Ù† Ø­Ø°Ù Ø´Ø¯
- Ø­Ø³Ø§Ø¨ Developer Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª ($100+/Ù…Ø§Ù‡)
- Rate limiting Ø´Ø¯ÛŒØ¯

### Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:

#### Ú¯Ø²ÛŒÙ†Ù‡ 1: API Ø±Ø³Ù…ÛŒ (Ù¾ÙˆÙ„ÛŒ)
```python
pip install tweepy
```

#### Ú¯Ø²ÛŒÙ†Ù‡ 2: Nitter (Scraping ØºÛŒØ±Ø±Ø³Ù…ÛŒ)
Nitter ÛŒÚ© frontend Ø¢Ø²Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Twitter Ø§Ø³Øª:

```python
import requests
from bs4 import BeautifulSoup

def scrape_twitter_via_nitter(username):
    url = f"https://nitter.net/{username}"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'lxml')

    tweets = []
    for tweet in soup.find_all('div', class_='tweet-content'):
        tweets.append(tweet.get_text(strip=True))

    return tweets
```

#### Ú¯Ø²ÛŒÙ†Ù‡ 3: snscrape (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ scraping)
```bash
pip install snscrape
```

```python
import snscrape.modules.twitter as sntwitter

# Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± ØªÙˆÛŒÛŒØªØ±
query = "Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ Ø®Ø±Ø§Ø³Ø§Ù†"
tweets = []

for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
    if i > 100:  # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯
        break

    tweets.append({
        'date': tweet.date,
        'text': tweet.rawContent,
        'user': tweet.user.username,
        'url': tweet.url
    })
```

---

## 3ï¸âƒ£ Instagram (Ø®ÛŒÙ„ÛŒ Ø³Ø®Øª)

### Ù…Ø´Ú©Ù„Ø§Øª:
- Anti-bot Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ
- Ù†ÛŒØ§Ø² Ø¨Ù‡ login
- Rate limiting Ø´Ø¯ÛŒØ¯
- Ø®Ø·Ø± ban Ø´Ø¯Ù† Ø§Ú©Ø§Ù†Øª

### Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§:

#### Instaloader
```bash
pip install instaloader
```

```python
import instaloader

L = instaloader.Instaloader()

# Login (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ù…Ø§ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
L.login('your_username', 'your_password')

# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ù¾Ø±ÙˆÙØ§ÛŒÙ„
profile = instaloader.Profile.from_username(L.context, 'target_username')

for post in profile.get_posts():
    if 'Ø¢Ø¨ Ø®Ø±Ø§Ø³Ø§Ù†' in post.caption:
        print(f"Caption: {post.caption}")
        print(f"Likes: {post.likes}")
        print(f"URL: {post.url}")
```

âš ï¸ **Ù‡Ø´Ø¯Ø§Ø±**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø²ÛŒØ§Ø¯ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ ban Ø´Ø¯Ù† Ù…Ù†Ø¬Ø± Ø´ÙˆØ¯!

---

## 4ï¸âƒ£ YouTube (API Ø¹Ø§Ù„ÛŒ Ø¯Ø§Ø±Ø¯)

### YouTube Data API (Ø±Ø§ÛŒÚ¯Ø§Ù†)
```bash
pip install google-api-python-client
```

```python
from googleapiclient.discovery import build

api_key = 'YOUR_YOUTUBE_API_KEY'
youtube = build('youtube', 'v3', developerKey=api_key)

# Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± YouTube
request = youtube.search().list(
    part='snippet',
    q='Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ Ø®Ø±Ø§Ø³Ø§Ù† Ø±Ø¶ÙˆÛŒ',
    type='video',
    maxResults=50
)

response = request.execute()

for item in response['items']:
    print(f"Title: {item['snippet']['title']}")
    print(f"URL: https://youtube.com/watch?v={item['id']['videoId']}")
```

---

## 5ï¸âƒ£ Reddit (API Ø±Ø§ÛŒÚ¯Ø§Ù†)

### PRAW (Python Reddit API Wrapper)
```bash
pip install praw
```

```python
import praw

reddit = praw.Reddit(
    client_id='YOUR_CLIENT_ID',
    client_secret='YOUR_CLIENT_SECRET',
    user_agent='my_scraper'
)

# Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± subreddit
for submission in reddit.subreddit('all').search('Khorasan water', limit=100):
    print(f"Title: {submission.title}")
    print(f"URL: {submission.url}")
    print(f"Score: {submission.score}")
```

---

## 6ï¸âƒ£ LinkedIn (ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ ØºÛŒØ±Ù…Ù…Ú©Ù†)

â›” **ØªÙˆØµÛŒÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯:**
- Anti-bot Ø¨Ø³ÛŒØ§Ø± Ù¾ÛŒØ´Ø±ÙØªÙ‡
- Ù†ÛŒØ§Ø² Ø¨Ù‡ login ÙˆØ§Ù‚Ø¹ÛŒ
- Ø®Ø·Ø± ban Ø¯Ø§Ø¦Ù…ÛŒ
- Ù†Ù‚Ø¶ Terms of Service

---

## ğŸ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¨Ø±Ø§ÛŒ "Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ Ø®Ø±Ø§Ø³Ø§Ù† Ø±Ø¶ÙˆÛŒ"

### Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ØªØ±Ú©ÛŒØ¨ÛŒ:

```python
#!/usr/bin/env python3
"""
Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø®Ø¨Ø§Ø± Ø§Ø² Ú†Ù†Ø¯ Ù…Ù†Ø¨Ø¹
"""

import asyncio
from telethon import TelegramClient
import json
from datetime import datetime

class MultiSourceScraper:
    def __init__(self):
        self.results = []

    async def scrape_telegram(self, channels, keywords):
        """Ø§Ø³Ú©Ø±Ù¾ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…"""
        api_id = 'YOUR_API_ID'
        api_hash = 'YOUR_API_HASH'

        client = TelegramClient('session', api_id, api_hash)
        await client.start()

        for channel in channels:
            try:
                async for msg in client.iter_messages(channel, limit=100):
                    if msg.text and any(kw in msg.text for kw in keywords):
                        self.results.append({
                            'source': 'Telegram',
                            'channel': channel,
                            'text': msg.text,
                            'date': msg.date.isoformat(),
                            'url': f"https://t.me/{channel.replace('@', '')}/{msg.id}"
                        })
            except:
                pass

        await client.disconnect()

    def scrape_youtube(self, query):
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± YouTube"""
        # Ú©Ø¯ YouTube API
        pass

    def scrape_reddit(self, query):
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Reddit"""
        # Ú©Ø¯ Reddit API
        pass

    async def run(self):
        keywords = ['Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ', 'Ø®Ø±Ø§Ø³Ø§Ù† Ø±Ø¶ÙˆÛŒ']
        telegram_channels = ['@abfa_news', '@khorasan_news']

        # Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ
        await asyncio.gather(
            self.scrape_telegram(telegram_channels, keywords),
            # Ø³Ø§ÛŒØ± Ù…Ù†Ø§Ø¨Ø¹...
        )

        return self.results

# Ø§Ø¬Ø±Ø§
scraper = MultiSourceScraper()
results = asyncio.run(scraper.run())
print(json.dumps(results, ensure_ascii=False, indent=2))
```

---

## ğŸ” Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ùˆ Ø§Ø®Ù„Ø§Ù‚ÛŒ

### âœ… Ù…Ø¬Ø§Ø²:
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ù‡Ø§ÛŒ Ø±Ø³Ù…ÛŒ
- Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
- Ø±Ø¹Ø§ÛŒØª Terms of Service
- Ø±Ø¹Ø§ÛŒØª Rate Limits

### âŒ ØºÛŒØ±Ù…Ø¬Ø§Ø²:
- Ù†Ù‚Ø¶ Terms of Service
- Ø¯ÙˆØ± Ø²Ø¯Ù† Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
- Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø®ØµÙˆØµÛŒ
- Ø§Ø³ØªÙØ§Ø¯Ù‡ ØªØ¬Ø§Ø±ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø¬ÙˆØ²

---

## ğŸ“¦ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡

```bash
# Telegram (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†)
pip install telethon pyrogram

# Twitter
pip install snscrape tweepy

# Instagram (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…Ø­ØªØ§Ø·Ø§Ù†Ù‡)
pip install instaloader

# YouTube
pip install google-api-python-client

# Reddit
pip install praw

# Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
pip install beautifulsoup4 lxml requests
```

---

## ğŸ¯ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ù…Ø§

Ø¨Ø±Ø§ÛŒ "Ø¢Ø¨ Ù…Ù†Ø·Ù‚Ù‡â€ŒØ§ÛŒ Ø®Ø±Ø§Ø³Ø§Ù† Ø±Ø¶ÙˆÛŒ":

1. **Ø§ÙˆÙ„ÙˆÛŒØª 1: Telegram** â­â­â­â­â­
   - API Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯
   - Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ Ø²ÛŒØ§Ø¯
   - Ø¨Ø¯ÙˆÙ† Ù…Ø­Ø¯ÙˆØ¯ÛŒØª

2. **Ø§ÙˆÙ„ÙˆÛŒØª 2: ScrapingDog API** â­â­â­â­
   - Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ
   - Ù‡Ù…Ø§Ù† workflow Ú©Ù‡ Ø³Ø§Ø®ØªÛŒÙ…

3. **Ø§ÙˆÙ„ÙˆÛŒØª 3: Twitter/X** â­â­â­
   - Ø§Ú¯Ø± API key Ø¯Ø§Ø±ÛŒØ¯
   - ÛŒØ§ Ø§Ø² snscrape

4. **Ø§ÙˆÙ„ÙˆÛŒØª 4: YouTube** â­â­
   - Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø¨Ø±ÛŒ

---

**Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ÛŒÚ© workflow ØªØ±Ú©ÛŒØ¨ÛŒ Ø¨Ø³Ø§Ø²Ù… Ú©Ù‡ Ø§Ø² Telegram + ScrapingDog Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯ØŸ**
